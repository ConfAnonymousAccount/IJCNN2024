{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model long COVID Intensity using Gradient Boosting (GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from package.data.utils import *\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from package.data.lifeline_dataset import LifeLineDataSet\n",
    "from package.data.data_manager import DataManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = pathlib.Path().absolute().parent.parent.parent\n",
    "dataset = LifeLineDataSet(data_path=data_path / \"data\" / \"extract\" / \"merged\", \n",
    "                          dataset_name=\"merged_vaccin_only_1_full.csv\",\n",
    "                          target_variable=\"long_covid_intensity\")\n",
    "dataset.get_encoded_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_manager = DataManager()\n",
    "data_manager.split_data_train_val_test(dataset, train_size=0.7, val_test_prop=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_manager.train_dataset.features.shape)\n",
    "print(data_manager.val_dataset.features.shape)\n",
    "print(data_manager.test_dataset.features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.model.stat_models import StatisticalModels\n",
    "from package.model.statistical_models.gradient_boosting_regressor import StatGradientBoostingRegressor\n",
    "from package.data.scaler import StandardScaler\n",
    "from package.data.utils import round_off_rating\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = pathlib.Path().resolve().parent / \"configurations\" / \"models\" / \"gradient_boosting.ini\"\n",
    "\n",
    "gb_model = StatisticalModels(StatGradientBoostingRegressor,\n",
    "                             config_path=CONFIG_PATH,\n",
    "                             config_name=\"DEFAULT\",\n",
    "                             name=\"gradient_boosting\",\n",
    "                             #scaler=StandardScaler\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model.train(data_manager.train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict using test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gb_model.predict(data_manager.test_dataset)\n",
    "y_predict_rounded = np.array([round_off_rating(el) for el in predictions])\n",
    "test_labels_rounded = np.array([round_off_rating(el) for el in data_manager.test_dataset.targets.ravel()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the evaluation criteria using predictions obtained using GB model and ground-truth observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.model.utils import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics(test_labels_rounded, y_predict_rounded, index=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model interpretation \n",
    "Visualize the feature importances obtained using GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.model.random_forest import plot_feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(gb_model._model.model.feature_importances_, dataset.feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = pathlib.Path().resolve().parent / \"configurations\" / \"models\" / \"gradient_boosting.ini\"\n",
    "\n",
    "rf_model = StatisticalModels(StatGradientBoostingRegressor,\n",
    "                             config_path=CONFIG_PATH,\n",
    "                             config_name=\"DEFAULT\",\n",
    "                             name=\"gradient_boosting\",\n",
    "                             #scaler=StandardScaler\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics, models, predictions, true_labels = gb_model.cross_validate(dataset, n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.model.utils import compute_metrics\n",
    "maes = []\n",
    "pearson_tests = []\n",
    "test_value = []\n",
    "p_values = []\n",
    "for i in range(5):\n",
    "    metrics = compute_metrics(true_labels[i], predictions[i], index=-1)\n",
    "    maes.append(metrics[\"mape\"])\n",
    "    pearson_tests.append(metrics[\"pearson\"])\n",
    "    test_value.append(pearson_tests[i].statistic)\n",
    "    p_values.append(pearson_tests[i].pvalue)\n",
    "print(np.mean(test_value))\n",
    "print(np.mean(p_values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lifeline",
   "language": "python",
   "name": "lifeline"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
